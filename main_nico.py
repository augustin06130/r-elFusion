import os
import sys
from openai import OpenAI

# Import des modules personnalis√©s
from config import parse_arguments, CLIENT_ID_REDDIT, CLIENT_SECRET_REDDIT
from reddit_client import setup_reddit, get_reddit_text
from text_processor import clean_reddit_text, split_text_into_chunks, setup_nltk
from translator import translate_text_safely_gpt
from media_generator import text_to_speech, create_video

def main():
    # Analyser les arguments
    args = parse_arguments()

    # Cr√©er le dossier de sortie s'il n'existe pas
    os.makedirs(args.output_dir, exist_ok=True)

    # Initialiser le client OpenAI
    client = OpenAI(api_key=args.openai_api_key)

    # Se connecter √† Reddit
    reddit = setup_reddit(CLIENT_ID_REDDIT, CLIENT_SECRET_REDDIT)
    if not reddit:
        print("‚ùå Impossible de se connecter √† Reddit. V√©rifiez vos identifiants.")
        return

    # R√©cup√©rer le post
    post_id, reddit_text = get_reddit_text(
        reddit,
        args.subreddit,
        args.keyword,
        args.limit
    )
    if not post_id:
        print("‚ùå Aucun post trouv√© correspondant aux crit√®res.")
        return

    # Nettoyer le texte
    cleaned = clean_reddit_text(reddit_text)

    # Traduire le texte avec GPT
    try:
        # V√©rifier que la cl√© API est pr√©sente
        if not args.openai_api_key:
            print("‚ùå Cl√© API OpenAI manquante. Utilisez --openai_api_key pour fournir votre cl√©.")
            return

        translated = translate_text_safely_gpt(
            cleaned,
            client,
            args.gpt_model,
            max_tokens=4096,
            max_chars=args.max_chars
        )
    except Exception as e:
        print(f"‚ùå Erreur fatale lors de la traduction avec GPT: {e}")
        return

    # D√©couper le texte en morceaux
    chunks = split_text_into_chunks(translated, args.chunk_size)
    if not chunks:
        print("‚ùå Aucun segment g√©n√©r√© apr√®s d√©coupage.")
        return

    # Pr√©visualiser les segments
    for i, chunk in enumerate(chunks):
        word_count = len(chunk.split())
        preview = chunk[:150] + "..." if len(chunk) > 150 else chunk
        print(f"\n--- Segment {i+1}/{len(chunks)} ({word_count} mots) ---")
        print(preview)

    # Cr√©ation des vid√©os pour chaque segment
    success_count = 0
    for i, chunk in enumerate(chunks):
        segment_num = i + 1
        print(f"\n=== Traitement du segment {segment_num}/{len(chunks)} ===")

        # Fichiers temporaires pour ce segment
        audio_file = os.path.join(args.output_dir, f"audio_{post_id}_{segment_num}.mp3")
        video_file = os.path.join(args.output_dir, f"video_{post_id}_{segment_num}.mp4")

        # G√©n√©ration de l'audio
        print(f"üîä Cr√©ation de la voix pour le segment {segment_num}...")
        if not text_to_speech(chunk, audio_file):
            print(f"‚ö†Ô∏è Pass√© au segment suivant.")
            continue

        # Cr√©ation de la vid√©o
        if create_video(audio_file, args.background, video_file):
            success_count += 1
            print(f"‚úÖ Vid√©o {segment_num} cr√©√©e: {video_file}")
        else:
            print(f"‚ùå √âchec de la cr√©ation de la vid√©o {segment_num}")

    # R√©sum√© final
    print(f"\n====== R√âSUM√â ======")
    print(f"Post: {post_id}")
    print(f"Mod√®le GPT utilis√©: {args.gpt_model}")
    print(f"Segments trait√©s: {len(chunks)}")
    print(f"Vid√©os cr√©√©es avec succ√®s: {success_count}")
    print(f"Dossier de sortie: {os.path.abspath(args.output_dir)}")
    print("===================")

if __name__ == "__main__":
    # Configuration initiale de NLTK
    setup_nltk()

    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Programme interrompu par l'utilisateur.")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur non g√©r√©e: {e}")
        sys.exit(1)
